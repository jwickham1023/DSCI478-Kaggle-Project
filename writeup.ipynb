{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "# DSCI478 Kaggle Project - Credit Card Fraud Detection\n",
    "### Nick Brady, Jakob Wickham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for us:\n",
    "- If you want the PDF to not display a cell, click the three dots on the cell, click \"Add Cell Tag\", and put \"remove_cell\"\n",
    "- If you want to hide the code instead, put \"remove_input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Figure out which one to use\n",
    "# import torch as t\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRANSACTION_ID</th>\n",
       "      <th>TX_DATETIME</th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>TERMINAL_ID</th>\n",
       "      <th>TX_AMOUNT</th>\n",
       "      <th>TX_TIME_SECONDS</th>\n",
       "      <th>TX_TIME_DAYS</th>\n",
       "      <th>TX_FRAUD</th>\n",
       "      <th>TX_FRAUD_SCENARIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:31</td>\n",
       "      <td>596</td>\n",
       "      <td>3156</td>\n",
       "      <td>57.16</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01 00:02:10</td>\n",
       "      <td>4961</td>\n",
       "      <td>3412</td>\n",
       "      <td>81.51</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-01 00:07:56</td>\n",
       "      <td>2</td>\n",
       "      <td>1365</td>\n",
       "      <td>146.00</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01 00:09:29</td>\n",
       "      <td>4128</td>\n",
       "      <td>8737</td>\n",
       "      <td>64.49</td>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-01 00:10:34</td>\n",
       "      <td>927</td>\n",
       "      <td>9906</td>\n",
       "      <td>50.99</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754150</th>\n",
       "      <td>1754150</td>\n",
       "      <td>2018-09-30 23:56:36</td>\n",
       "      <td>161</td>\n",
       "      <td>655</td>\n",
       "      <td>54.24</td>\n",
       "      <td>15810996</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754151</th>\n",
       "      <td>1754151</td>\n",
       "      <td>2018-09-30 23:57:38</td>\n",
       "      <td>4342</td>\n",
       "      <td>6181</td>\n",
       "      <td>1.23</td>\n",
       "      <td>15811058</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754152</th>\n",
       "      <td>1754152</td>\n",
       "      <td>2018-09-30 23:58:21</td>\n",
       "      <td>618</td>\n",
       "      <td>1502</td>\n",
       "      <td>6.62</td>\n",
       "      <td>15811101</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754153</th>\n",
       "      <td>1754153</td>\n",
       "      <td>2018-09-30 23:59:52</td>\n",
       "      <td>4056</td>\n",
       "      <td>3067</td>\n",
       "      <td>55.40</td>\n",
       "      <td>15811192</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754154</th>\n",
       "      <td>1754154</td>\n",
       "      <td>2018-09-30 23:59:57</td>\n",
       "      <td>3542</td>\n",
       "      <td>9849</td>\n",
       "      <td>23.59</td>\n",
       "      <td>15811197</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754155 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRANSACTION_ID          TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  \\\n",
       "0                     0  2018-04-01 00:00:31          596         3156   \n",
       "1                     1  2018-04-01 00:02:10         4961         3412   \n",
       "2                     2  2018-04-01 00:07:56            2         1365   \n",
       "3                     3  2018-04-01 00:09:29         4128         8737   \n",
       "4                     4  2018-04-01 00:10:34          927         9906   \n",
       "...                 ...                  ...          ...          ...   \n",
       "1754150         1754150  2018-09-30 23:56:36          161          655   \n",
       "1754151         1754151  2018-09-30 23:57:38         4342         6181   \n",
       "1754152         1754152  2018-09-30 23:58:21          618         1502   \n",
       "1754153         1754153  2018-09-30 23:59:52         4056         3067   \n",
       "1754154         1754154  2018-09-30 23:59:57         3542         9849   \n",
       "\n",
       "         TX_AMOUNT  TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \n",
       "0            57.16               31             0         0                  0  \n",
       "1            81.51              130             0         0                  0  \n",
       "2           146.00              476             0         0                  0  \n",
       "3            64.49              569             0         0                  0  \n",
       "4            50.99              634             0         0                  0  \n",
       "...            ...              ...           ...       ...                ...  \n",
       "1754150      54.24         15810996           182         0                  0  \n",
       "1754151       1.23         15811058           182         0                  0  \n",
       "1754152       6.62         15811101           182         0                  0  \n",
       "1754153      55.40         15811192           182         0                  0  \n",
       "1754154      23.59         15811197           182         0                  0  \n",
       "\n",
       "[1754155 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Talk about the importance of fraud detection and fraud prevention*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*State the dataset was synthetically generated*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Load and Preprocess Data\n",
    "\n",
    "df.columns = df.columns.str.strip().str.upper()\n",
    "\n",
    "# Drop unnecessary column\n",
    "df.drop(columns=['TX_FRAUD_SCENARIO'], inplace=True)\n",
    "\n",
    "# Convert TX_DATETIME and extract key time features\n",
    "df['TX_DATETIME'] = pd.to_datetime(df['TX_DATETIME'])\n",
    "df['TX_HOUR'] = df['TX_DATETIME'].dt.hour\n",
    "df['TX_DAYOFWEEK'] = df['TX_DATETIME'].dt.dayofweek\n",
    "df.drop(columns=['TX_DATETIME'], inplace=True)\n",
    "\n",
    "\n",
    "# Time-Based Split\n",
    "split_point = df['TX_TIME_DAYS'].quantile(0.8)\n",
    "train_df = df[df['TX_TIME_DAYS'] < split_point].copy()\n",
    "test_df = df[df['TX_TIME_DAYS'] >= split_point].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dropping the TX_FRAUD_SCENARIO column and turning the TX_DATETIME column to a proper DateTime*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*General stuff, like fraud percentage, rolling window sample distributions, etc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Graphs such as ratio of fraud within sliding windows, and then some*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Imbalanced techniques, adding columns for rolling windows and sampling distribution z-scores, etc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Rolling Windows with decay\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_df['TX_AMOUNT_Z_SCORE'] = scaler.fit_transform(train_df[['TX_AMOUNT']])\n",
    "test_df['TX_AMOUNT_Z_SCORE'] = scaler.transform(test_df[['TX_AMOUNT']])\n",
    "\n",
    "train_df['TX_AMOUNT_PERCENTILE'] = train_df['TX_AMOUNT'].rank(pct=True)\n",
    "test_df['TX_AMOUNT_PERCENTILE'] = test_df['TX_AMOUNT'].rank(pct=True)\n",
    "\n",
    "\n",
    "# Optimize Decay Factor \n",
    "\n",
    "decay_values = np.linspace(0.8, 0.99, 20)  \n",
    "best_decay, best_corr = 0.95, float('-inf')  \n",
    "\n",
    "for decay in decay_values:\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['TERMINAL_FRAUD_RATIO_28D'] = (\n",
    "        temp_df.groupby('TERMINAL_ID')['TX_FRAUD']\n",
    "        .shift(1)\n",
    "        .ewm(alpha=1-decay)\n",
    "        .mean()\n",
    "    )\n",
    "    correlation = temp_df['TERMINAL_FRAUD_RATIO_28D'].corr(temp_df['TX_FRAUD'])\n",
    "    \n",
    "    if correlation > best_corr:\n",
    "        best_corr = correlation\n",
    "        best_decay = decay\n",
    "\n",
    "optimal_decay = best_decay  # Best decay factor based on correlation\n",
    "\n",
    "# Apply the optimized decay factor\n",
    "train_df['TERMINAL_FRAUD_RATIO_28D'] = (\n",
    "    train_df.groupby('TERMINAL_ID')['TX_FRAUD']\n",
    "    .shift(1)\n",
    "    .ewm(alpha=1-optimal_decay)\n",
    "    .mean()\n",
    ")\n",
    "test_df['TERMINAL_FRAUD_RATIO_28D'] = (\n",
    "    test_df.groupby('TERMINAL_ID')['TX_FRAUD']\n",
    "    .shift(1)\n",
    "    .ewm(alpha=1-optimal_decay)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Terminal Fraud Ratios\n",
    "train_df['TERMINAL_FRAUD_RATIO_7D'] = (\n",
    "    train_df.groupby('TERMINAL_ID')['TX_FRAUD']\n",
    "    .shift(1)\n",
    "    .rolling(7, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "test_df['TERMINAL_FRAUD_RATIO_7D'] = (\n",
    "    test_df.groupby('TERMINAL_ID')['TX_FRAUD']\n",
    "    .shift(1)\n",
    "    .rolling(7, min_periods=1)\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Customer Spending Trends\n",
    "train_df['SPENDING_RATIO_CHANGE'] = (\n",
    "    train_df.groupby('CUSTOMER_ID')['TX_AMOUNT']\n",
    "    .transform(lambda x: x.pct_change().rolling(14, min_periods=1).mean())\n",
    ")\n",
    "test_df['SPENDING_RATIO_CHANGE'] = (\n",
    "    test_df.groupby('CUSTOMER_ID')['TX_AMOUNT']\n",
    "    .transform(lambda x: x.pct_change().rolling(14, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "train_df['SPENDING_Z_SCORE_28D'] = (\n",
    "    train_df.groupby('CUSTOMER_ID')['TX_AMOUNT']\n",
    "    .transform(lambda x: (x - x.mean()) / (x.std() + 1))\n",
    ")\n",
    "test_df['SPENDING_Z_SCORE_28D'] = (\n",
    "    test_df.groupby('CUSTOMER_ID')['TX_AMOUNT']\n",
    "    .transform(lambda x: (x - x.mean()) / (x.std() + 1))\n",
    ")\n",
    "\n",
    "\n",
    "# Anomaly Detection (Local Outlier Factor)\n",
    "\n",
    "features_for_lof = ['TX_AMOUNT_Z_SCORE', 'SPENDING_RATIO_CHANGE', 'TERMINAL_FRAUD_RATIO_28D']\n",
    "train_df[features_for_lof] = train_df[features_for_lof].fillna(train_df[features_for_lof].median())\n",
    "test_df[features_for_lof] = test_df[features_for_lof].fillna(test_df[features_for_lof].median())\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.005, novelty=True)\n",
    "lof.fit(train_df[features_for_lof].values)\n",
    "\n",
    "train_df['ANOMALY_SCORE'] = lof.decision_function(train_df[features_for_lof].values)\n",
    "test_df['ANOMALY_SCORE'] = lof.decision_function(test_df[features_for_lof].values)\n",
    "\n",
    "# Normalize Anomaly Scores\n",
    "scaler = MinMaxScaler()\n",
    "train_df['ANOMALY_SCORE'] = scaler.fit_transform(train_df[['ANOMALY_SCORE']])\n",
    "test_df['ANOMALY_SCORE'] = scaler.transform(test_df[['ANOMALY_SCORE']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Isolation Forest, Balanced Random Forest, etc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation and Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Graphs such as feature importance and within-feature / within-fraud boxplots*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Talk about the three scenarios that we used to make a transaction fraud*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reproducible Machine Learning for Credit Card Fraud Detection - Practical Handbook\n",
    "    - Yann-AÃ«l Le Borgne, Wissam Siblini, Bertrand Lebichot, and Gianluca Bontempi\n",
    "    - https://github.com/Fraud-Detection-Handbook/fraud-detection-handbook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
